## 一个典型的服务器结构

<img src="G:\desktop\work\learning\study_point\Offer\大并发服务器开发.assets\image-20220429101756475.png" alt="image-20220429101756475" style="zoom:50%;" />

缓解数据库的压力 

1:队列 +连接池 DAL

2:主要的业务逻辑挪到应用服务器处理,数据库只做辅助的业务处理

3:缓存



针对缓存



缓存更新(缓存同步) 缓存 timeout

如果缓存失效,重新去数据库查询,  实时性比较差

一旦数据库中数据更新, 立即通知前端的缓存更新,实时性比较高



缓存换页, 内存不够  将不活跃的数据换出内存 

FIFO LRU(least recently used) LFU(least frequently used) 最不频繁使用



noSQL(反SQL) 	 key/value

分布式缓存 		redis		memcached



数据库的读写分离

数据库的读操作 > 写操作

对数据库进行负载均衡  replication机制   master/slave



应用服务器的负载均衡

增加一个任务服务器来实现, 任务服务器可以监视应用服务器的负载,CPU高 IO高 并发高 内存换页高

查询到这些信息之后,选取负载最低的服务器分配任务

应用服务器被动接受任务

应用服务器主动到任务服务器接收任务进行处理



服务器高性能编程

服务器性能四大杀手

数据拷贝   缓存

环境切换	(理性创建线程)该不该多线程,单线程好还是多线程好, 单核服务器(采用状态机编程,效率最佳),多线程能够充分发挥多核服务器的性能

内存分配	内存池

锁竞争



大量任务 提交到服务器

增加线程间的切换开销

进程切换

<img src="G:\desktop\work\learning\study_point\Offer\大并发服务器开发.assets\image-20220429101112894.png" alt="image-20220429101112894" style="zoom: 33%;" />

## 大型网站架构演变过程

step1:web server与数据库分离

<img src="G:\desktop\work\learning\study_point\Offer\大并发服务器开发.assets\image-20220429102834760.png" alt="image-20220429102834760" style="zoom:33%;" />

web动静资源分离

<img src="G:\desktop\work\learning\study_point\Offer\大并发服务器开发.assets\image-20220429104628706.png" alt="image-20220429104628706" style="zoom: 33%;" />

step2:缓存处理

<img src="G:\desktop\work\learning\study_point\Offer\大并发服务器开发.assets\image-20220429104926665.png" alt="image-20220429104926665" style="zoom: 33%;" />

step3:web server集群+读写分离

<img src="G:\desktop\work\learning\study_point\Offer\大并发服务器开发.assets\image-20220429105229962.png" alt="image-20220429105229962" style="zoom:33%;" />

<img src="G:\desktop\work\learning\study_point\Offer\大并发服务器开发.assets\image-20220429105551917.png" alt="image-20220429105551917" style="zoom: 50%;" />

step4:CDN、分布式缓存、分库分表

<img src="G:\desktop\work\learning\study_point\Offer\大并发服务器开发.assets\image-20220429105948460.png" alt="image-20220429105948460" style="zoom:33%;" />

分布式缓存

![image-20220429110111101](G:\desktop\work\learning\study_point\Offer\大并发服务器开发.assets\image-20220429110111101.png)

分库

<img src="G:\desktop\work\learning\study_point\Offer\大并发服务器开发.assets\image-20220429110301392.png" alt="image-20220429110301392" style="zoom: 50%;" />

<img src="G:\desktop\work\learning\study_point\Offer\大并发服务器开发.assets\image-20220429110328317.png" alt="image-20220429110328317" style="zoom:50%;" />

step5:多数据中心+分布式存储与计算

<img src="G:\desktop\work\learning\study_point\Offer\大并发服务器开发.assets\image-20220429110748215.png" alt="image-20220429110748215" style="zoom:33%;" />

技术点[DFS, Key-ValueDB, Map/Reduce]

<img src="G:\desktop\work\learning\study_point\Offer\大并发服务器开发.assets\image-20220429111520448.png" alt="image-20220429111520448" style="zoom: 67%;" />

## I/O复用

![image-20220505154508036](G:\desktop\work\learning\study_point\Offer\大并发服务器开发.assets\image-20220505154508036.png)

![image-20220505154516666](G:\desktop\work\learning\study_point\Offer\大并发服务器开发.assets\image-20220505154516666.png)

![image-20220505184625449](G:\desktop\work\learning\study_point\Offer\大并发服务器开发.assets\image-20220505184625449.png)

已连接套接字不太大,并且这些套接字非常活跃

poll select

一次性遍历返回 活跃的文件描述符



epoll内部的实现更复杂 ,更复杂的代码逻辑 callback保证活跃  处理大量连接时



![image-20220505184635829](G:\desktop\work\learning\study_point\Offer\大并发服务器开发.assets\image-20220505184635829.png)





![image-20220505154431466](G:\desktop\work\learning\study_point\Offer\大并发服务器开发.assets\image-20220505154431466.png)

EPOLL LT

![image-20220505154708507](G:\desktop\work\learning\study_point\Offer\大并发服务器开发.assets\image-20220505154708507.png)

EPOLL ET

![image-20220505154728032](G:\desktop\work\learning\study_point\Offer\大并发服务器开发.assets\image-20220505154728032.png)





### EPOLLIN事件

内核中的socket接受缓冲区  为空  		  低电平

内核中的socket接收缓冲区   不为空   	高电平

### EPOLLOUT事件

内核中的socket发送缓冲区	不满			高电平

内核中的socket发送缓冲区 	满				低电平



### LT 	电平触发

高电平触发

### ET 	边沿触发

低电平-->高电平	触发

高电平-->低电平	触发0



## TCP网络编程本质

### TCP网络编程最本质是的处理三个半事  件

**连接建立**：服务器accept（被动）接受连接，客户端connect（主动）发起连接
**连接断开**：主动断开（close、shutdown），被动断开（read返回0）
**消息到达**：文件描述符可读

**消息发送完毕**：这算半个。对于低流量的服务，可不必关心这个事件;这里的发送完毕是指数据写入操作系统缓冲区，将由TCP协议栈负责数据的发送与重传，不代表对方已经接收到数据。

![image-20220516102906901](G:\desktop\work\learning\study_point\Offer\大并发服务器开发.assets\image-20220516102906901.png) 



## EchoServer类图

面向对象风格,用一个EchoServer继承TcpSever(抽象类),实现三个接口onConnection,onMessage,onClose

基于对象风格,用一个EchoServer包含一个TcpServer(具体类),在构造函数中用boost::bind来注册三个成员函数onConnection,onMessage,onClose

![image-20220516103055977](G:\desktop\work\learning\study_point\Offer\大并发服务器开发.assets\image-20220516103055977.png)

## 什么都不做的EventLoop

Multiple reactors + threadpool(**one loop  per thread**)意思是说每个线程最多只能有一个EventLoop对象。(reactor 线程)
EventLoop对象构造的时候，会检查当前线程是否已经创建了其他EventLoop对象，如果已创建，终止程序（LOG_FATAL）
EventLoop构造函数会记住本对象所属线程（threadId_）。
**创建了EventLoop对象的线程称为IO线程**，其功能是运行事件循环（EventLoop::loop） 



## 类图

![image-20220516124352336](G:\desktop\work\learning\study_point\Offer\大并发服务器开发.assets\image-20220516124352336.png)

Channel是selectable IO channel，负责注册与响应IO 事件，它不拥有file descriptor。
Channel是Acceptor、Connector、EventLoop、TimerQueue、TcpConnection的成员，生命期由后者控制。

![image-20220516125236036](G:\desktop\work\learning\study_point\Offer\大并发服务器开发.assets\image-20220516125236036.png)

## 总结一下

### 使用流程

a.首先定义一个EventLoop(baseLoop), InetAddress,创建了一个server(构造函数由给定的参数初始化底层的server,相当于创建了一个TCPserver对象,)

b.然后设置回调,设置底层loop线程数量

c.分离了网络和开发,开发者只要关注onConnection方法,关注连接建立或者断开的回调以及可读写事件回调等

d.最后,调用server的start,启动loop

###  TcpServer

1.首先创建acceptor对象--->

accept->流程

创建一个非阻塞的Fd,打包成一个Channel(,往mainLoop的poll上扔.),然后设置一些tcp选项(Addr,Port),bind绑定了ListenAddr,,接着设置了一个关键的setReadCallback回调(也就是说网络连接的时候 accpt channel只关心读事件,执行Acceptor::handleRead)

(这里acceptChannel_.setReadCallback,当有新用户连接的时候,底层的channel就回去执行readCallback事件,也就是这里的Acceptor::handleRead,而这个handleRead也就newConnectionCallback (这个回调是accept设置的,而accept又是有TcpServer管理的,即TCPServer设置的))

2.然后创建threadPool-->

当前还没有开启loop线程

3.接着acceptor_->setNewConnectionCallback(这里就对应到了TcpServer::newConnection的回调)

4.接下来设置newConnectionCallBack, setTreadNum

5.设置start

这里通过atomic变量started 在一个线程里面只能只能去调用一次tcp::server的strat

a. threadPool_->start(threadInitCallback_); // 启动底层的loop线程池

-->创建loop子线程并开启loop.loop()

-->为了唤醒subloop, 每个线程都有一个wake_up fd注册在相应的loop的poll上

b.loop_->runInLoop(std::bind(&Acceptor::listen, acceptor_.get()))

-->把Acceptor::listen注册在baseloop上

6.最后就是baseloop.loop(),开启loop

#### 小结一下

listenfd

bind

setsockoption

setReadCallback-->handleRead-->newConnectionCallback

​																				|

​																				V

​															TCPServer的构造函数中

​															acceptor->setNewConnetionCallback

​																				|

​											     响应				    	V												轮询算法选择subLoop<-ioLoop

​				 	有新用户连接--------------->TCP Server::newConnetion		--------> 创建TcpConnetion对象

​																																	 注册回调

​																									          	close的回调->TcpServer::removeConnection

​																					    	ioLoop->runInLoop->TcpConnection::connetEstablished

​                                                                                             连接建立----->TcpConnection::connectEstablished

1.防止意外tcpconnetion被杀死 用channel的tie的弱智能指针绑定

2.channel_->enableReading 然后向poller注册channel的epollin事件 (即注册到某个选择的subloop上)更新

3.执行新连接建立，执行回调   connectionCallback  连接成功

4.conn->shutdown--->执行TCP Server::removeConnetion ---> removeConnectionInLoop--->然后onnections_.erase(conn->name())--->ioLoop = conn->getLoop(获取连接的subLoop)--->TcpConnection::connectDestroyed--->设置状态和channel_->disableAll---> channel_->remove()(把channel从poller中删除掉)